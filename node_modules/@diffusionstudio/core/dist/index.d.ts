import { BaseEvents } from '../mixins/event/types';
import { BaseEvents as BaseEvents_2 } from '../../mixins/event/types';
import { BlendMode as BlendMode_2 } from '../..';
import { ClipAnimationOptions as ClipAnimationOptions_2 } from '..';
import { ClipType as ClipType_2 } from '../..';
import { EmittedEvent } from '../mixins/event/types';
import { EmittedEvent as EmittedEvent_2 } from '../../mixins/event/types';
import { frame as frame_2 } from '..';
import { int as int_2 } from '../..';
import { Mask as Mask_2 } from '../..';
import { MediaInput as MediaInput_2 } from '../..';
import { Percent as Percent_2 } from '../..';
import { Point as Point_2 } from '../..';
import { RelativePoint as RelativePoint_2 } from '../..';
import { Size as Size_2 } from '../..';
import { SourceInitOptions as SourceInitOptions_2 } from '..';
import { SourceInitOptions as SourceInitOptions_3 } from './base';
import { Timestamp as Timestamp_2 } from '../..';
import { Token } from '../../nodes/text/token';
import { WrappedCanvas } from '../../lib/metamuxer';

export declare function abs(value: number | Percent, max: number): number;

/**
 * List of all track types.
 * @public
 */
declare const ALL_TRACK_TYPES: readonly ["video", "audio", "subtitle"];

/**
 * Move an element inside the provided array
 */
export declare function arraymove(arr: any[], fromIndex: number, toIndex: number): void;

/**
 * clip assert replacement for the browser
 * @example assert(true == false)
 */
export declare function assert(condition: any, message?: string): asserts condition;

export declare function assertNever(_: never): void;

/**
 * List of known audio codecs, ordered by encoding preference.
 * @public
 */
declare const AUDIO_CODECS: readonly ["aac", "opus", "mp3", "vorbis", "flac", "pcm-s16", "pcm-s16be", "pcm-s24", "pcm-s24be", "pcm-s32", "pcm-s32be", "pcm-f32", "pcm-f32be", "pcm-u8", "pcm-s8", "ulaw", "alaw"];

export declare const AUDIO_LOOK_AHEAD = 0.2;

/**
 * Converts the specified AudioBuffer to a Blob.
 *
 * Note that changing the MIME type does not change the actual file format.
 * The output is a WAVE in any case
 */
export declare function audioBufferToWav(buffer: AudioBuffer, type?: string): Blob;

export declare class AudioClip extends Clip {
    private _muted;
    private _volume;
    private _transcript?;
    protected gainNode?: GainNode;
    readonly type: ClipType;
    layer?: Layer<AudioClip>;
    source?: AudioSource;
    playing: boolean;
    /**
     * Defines the start and stop values of the clip
     * relative to the delay (which part of the media should be played)
     */
    range: [Timestamp, Timestamp];
    /**
     * Defines the playback element
     */
    element?: HTMLAudioElement | HTMLVideoElement;
    constructor(input?: MediaInput | AudioSource, props?: AudioClipProps);
    init(audio: AudioRenderer): Promise<void>;
    play(audio: AudioRenderer): Promise<void>;
    pause(): Promise<void>;
    enter(audio: AudioRenderer): Promise<void>;
    update(audio: AudioRenderer): Promise<void>;
    exit(): Promise<void>;
    /**
     * Defines the transcript of the video/audio.
     * Will be trimmed to the clip range.
     * If the duration is not set, the transcript will be returned.
     */
    get transcript(): Transcript | undefined;
    set transcript(transcript: Transcript | undefined);
    cleanup(): void;
    get start(): Timestamp;
    get stop(): Timestamp;
    get duration(): Timestamp;
    set duration(time: Time);
    /**
     * Number between 0 and 1 defining the volume of the media
     * @default 1
     */
    get volume(): number;
    set volume(value: number);
    get muted(): boolean;
    set muted(value: boolean);
    trim(start?: Time, stop?: Time): this;
    /**
     * Returns a slice of a media clip with trimmed start and stop
     */
    subclip(start?: Time, stop?: Time): this;
    split(time?: Time): Promise<this>;
    /**
     * Remove silences from the clip will return an array of clips with the silences removed.
     * If the clip has been added to a layer it will remove the silences within the layer.
     * @param options - Options for silence detection
     */
    removeSilences(options?: SilenceRemoveOptions): Promise<AudioClip[]>;
    /**
     * Get the range of the clip in **seconds**
     */
    protected getBufferRange(audio: AudioRenderer): [number, number];
}

export declare interface AudioClipProps extends ClipProps {
    playing?: boolean;
    transcript?: Transcript;
    volume?: number;
    muted?: boolean;
}

/**
 * Union type of known audio codecs.
 * @public
 */
declare type AudioCodec = typeof AUDIO_CODECS[number];

declare interface AudioConfig {
    /**
     * Enable audio encoding
     * @default true
     */
    enabled?: boolean;
    /**
     * A floating point number indicating the audio context's sample rate, in samples per second.
     * @default 48000
     */
    sampleRate?: number;
    /**
     * Defines the number of channels of the composed audio
     * @default 2
     */
    numberOfChannels?: number;
    /**
     * Defines the bitrate at which the audio should be rendered at
     * @default 128e3
     */
    bitrate?: number;
    /**
     * Defines the codec to use for the audio
     * @default 'aac'
     */
    codec?: AudioCodec;
}

/**
 * Web Audio API based audio renderer
 */
export declare class AudioRenderer {
    readonly context: AudioContext | OfflineAudioContext;
    /**
     * Offset in **seconds** relative to the hardware time when the playback started
     */
    hardwareOffset: number;
    /**
     * Offset in **seconds** relative to 0 when the playback started
     */
    playbackOffset: number;
    /**
     * Defines the fps used for rendering.
     */
    playbackFps: float;
    /**
     * The fps used when the ticker is inactive (not playing)
     */
    inactiveFps: number;
    /**
     * Defines the current state of the ticker
     */
    playing: boolean;
    /**
     * Defines if the ticker is active
     */
    stopped: boolean;
    /**
     * User defined fixed duration
     *
     * @deprecated Use markers.stop instead
     */
    duration?: Timestamp;
    /**
     * The function to call when the ticker is updated
     */
    private callback;
    /**
     * The last time the timer was updated
     */
    private lastFrameTime;
    /**
     * Creates a new ticker
     * @param callback - The function to call when the ticker is updated
     */
    constructor(options?: AudioRendererInit);
    /**
     * The current time of the hardware in seconds
     */
    get hardwareTime(): number;
    /**
     * The current time of the playback in **seconds** relative to 0
     */
    get playbackTime(): number;
    get playbackTimestamp(): Timestamp;
    /**
     * The current frame that the playback is set to
     */
    get playbackFrame(): frame;
    /**
     * Starts the animation loop
     */
    start(): void;
    /**
     * Stops the animation loop
     */
    stop(): void;
    /**
     * Starts the frame incrementation
     */
    play(): Promise<void>;
    /**
     * Pauses the frame incrementation
     */
    pause(): Promise<void>;
    /**
     * The animation loop
     */
    private timer;
    private resumeAudioContext;
}

declare type AudioRendererInit = {
    fps?: number;
    callback?(): Promise<void>;
    context?: AudioContext | OfflineAudioContext;
};

export declare type AudioSlice = {
    start: Timestamp;
    stop: Timestamp;
};

export declare class AudioSource extends BaseSource {
    readonly type: ClipType;
    element: HTMLAudioElement | HTMLVideoElement;
    decoder: WebAudioDecoder;
    duration?: Timestamp;
    demuxer?: Promise<Input>;
    transcript?: Transcript;
    constructor(options: SourceOptions);
    init(options?: SourceInitOptions): Promise<void>;
    decode(numberOfChannels?: number, sampleRate?: number, cache?: boolean): Promise<AudioBuffer>;
    /**
     * Find silences in the audio clip. Results are cached.
     *
     * uses default sample rate of 3000
     * @param options - Silences options.
     * @returns An array of the silences (in ms) in the clip.
     */
    silences(options?: SilenceDetectionOptions): Promise<AudioSlice[]>;
    /**
     * Sampler that uses a window size to calculate the max value of the samples in the window.
     * @param options - Sampling options.
     * @returns An array of the max values of the samples in the window.
     */
    sample({ length, start, stop, logarithmic, }?: SamplerOptions): Promise<Float32Array>;
    thumbnail(options?: SamplerOptions): Promise<HTMLElement>;
}

export declare type Background = {
    /**
     * @default #000000
     */
    fill?: hex;
    /**
     * @default 100
     */
    opacity?: number;
    /**
     * @default 20
     */
    borderRadius?: number;
    /**
     * @default { x: 30, y: 20 }
     */
    padding?: {
        x: int;
        y: int;
    };
};

export declare class BaseError extends Error {
    readonly message: string;
    readonly code: string;
    constructor({ message, code }: {
        message?: string | undefined;
        code?: string | undefined;
    }, ...args: any[]);
}

declare type BaseEvents_3<E = {}> = {
    '*': any;
    error: Error;
} & E;

export declare class BaseSource extends Serializer {
    /**
     * Unique identifier of the source
     */
    id: string;
    /**
     * Data associated with the source
     */
    data: Record<string, unknown>;
    readonly type: ClipType;
    mimeType: string;
    input: MediaInput;
    name: string;
    createdAt: Date;
    constructor(options: SourceOptions);
    init(options?: SourceInitOptions): Promise<void>;
    /**
     * Get the source as an array buffer
     */
    arrayBuffer(): Promise<ArrayBuffer>;
    /**
     * Downloads the file
     */
    download(): Promise<void>;
    /**
     * Get a visulization of the source
     * as an html element
     * @deprecated
     */
    thumbnail(): Promise<HTMLElement>;
    /**
     * Create a checkpoint of the source. May include Blob or FileSystemFileHandle.
     * @param middleware A function to modify the checkpoint data
     * @returns A serialized representation of the source
     */
    createCheckpoint(): Promise<unknown>;
}

/**
 * Defines the blend mode to use
 */
export declare type BlendMode = 'source-over' | 'source-in' | 'source-out' | 'source-atop' | 'destination-over' | 'destination-in' | 'destination-out' | 'destination-atop' | 'lighter' | 'copy' | 'xor' | 'multiply' | 'screen' | 'overlay' | 'darken' | 'lighten' | 'color-dodge' | 'color-burn' | 'hard-light' | 'soft-light' | 'difference' | 'exclusion' | 'hue' | 'saturation' | 'color' | 'luminosity';

/**
 * Merges the channels of the audio blob into a mono AudioBuffer
 */
export declare function blobToMonoBuffer(blob: Blob, sampleRate?: number, scalingFactor?: number): Promise<AudioBuffer>;

/**
 * Convert an audio buffer into a planar float 32 array
 */
export declare function bufferToF32Planar(input: AudioBuffer): Float32Array;

/**
 * Conver an audio buffer inter a interleaved int 16 array
 */
export declare function bufferToI16Interleaved(audioBuffer: AudioBuffer): Int16Array;

export declare function capitalize(str: string): string;

export declare class CaptionPreset {
    /**
     * This function returns the position of the captions
     */
    position: RelativePoint;
    constructor(config?: CaptionPresetConfig);
    /**
     * This function syncs the timestamp of the captions to the audio clip
     * @param layer - The layer to sync
     * @param clip - The audio clip to sync to
     */
    sync(layer: Layer, clip: AudioClip): this;
    /**
     * This function creates the captions
     * @param layer - The layer to apply the settings to
     * @param transcript - The transcript to apply the settings to
     * @param offset - The offset of the captions
     */
    apply(layer: Layer, transcript: Transcript, offset: Timestamp): Promise<void>;
}

export declare interface CaptionPresetConfig {
    position?: RelativePoint;
}

/**
 * Defines the captions transport format
 */
export declare type Captions = {
    /**
     * Defines the word or token
     * currently spoken
     */
    token: string;
    /**
     * Defines the time when the token
     * will be spoken in **milliseconds**
     */
    start: number;
    /**
     * Defines the time when the token
     * has been spoken in **milliseconds**
     */
    stop: number;
}[][];

export declare class CascadeCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    constructor(config?: DefaultCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

/**
 * Defines the properties of a circle
 */
export declare interface Circle {
    /**
     * The x coordinate of the circle
     */
    cx: number | Percent;
    /**
     * The y coordinate of the circle
     */
    cy: number | Percent;
    /**
     * The radius of the circle
     */
    radius: number | Percent;
}

export declare class CircleClip extends ShapeClip {
    _keepAspectRatio: boolean;
    readonly type = "circle";
    layer?: Layer<CircleClip>;
    animations: CircleClipAnimationOptions;
    constructor(props?: CircleClipProps);
    get radius(): number;
    set radius(value: number | Percent);
    get name(): string;
    /**
     * Access to the html document that
     * will be rendered to the canvas
     */
    render(renderer: VideoRenderer): void;
}

export declare type CircleClipAnimationOptions = (KeyframeOptions<'x' | 'y' | 'translateX' | 'translateY' | 'width' | 'height', number | Percent> | KeyframeOptions<'opacity' | 'rotation' | 'scale' | 'scaleX' | 'scaleY' | 'radius', number> | KeyframeOptions<'fill', string>)[];

export declare interface CircleClipProps extends ShapeClipProps {
    radius?: number | Percent;
    animations?: CircleClipAnimationOptions;
}

export declare class CircleMask extends Mask {
    readonly type: MaskType;
    /**
     * @deprecated Use `x` instead
     */
    cx: number | Percent;
    /**
     * @deprecated Use `y` instead
     */
    cy: number | Percent;
    animations: CircleMaskAnimationOptions;
    constructor({ cx, cy, x, y, radius, animations, ...props }?: CircleMaskProps);
    set x(value: number | Percent);
    set y(value: number | Percent);
    get x(): number | Percent;
    get y(): number | Percent;
    get radius(): number;
    set radius(value: number | Percent);
    draw(renderer: VideoRenderer): Path2D;
    get bounds(): [Point, Point, Point, Point];
}

export declare type CircleMaskAnimationOptions = KeyframeOptions<'x' | 'y' | 'cx' | 'cy' | 'radius' | 'width' | 'height', number | Percent>[];

export declare interface CircleMaskProps extends MaskProps {
    cx?: number | Percent;
    cy?: number | Percent;
    x?: number | Percent;
    y?: number | Percent;
    radius?: number | Percent;
    animations?: CircleMaskAnimationOptions;
}

export declare function clamp(t: number, a: number, b: number): number;

export declare class ClassicCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    constructor(config?: DefaultCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

export declare class Clip extends Clip_base {
    /**
     * Unique identifier of the clip
     */
    id: string;
    _name: undefined | string;
    _delay: Timestamp;
    _duration: Timestamp;
    /**
     * Data associated with the clip
     */
    data: Record<string, unknown>;
    /**
     * Flag to check if the clip has been initialized
     */
    initialized: boolean;
    /**
     * Defines the type of the clip
     */
    readonly type: ClipType;
    /**
     * Defines the source of the clip which can be
     * shared with other clips for more efficient
     * memory usage
     */
    source?: BaseSource;
    /**
     * Timestamp when the clip has been created
     */
    readonly createdAt: Date;
    /**
     * Controls the visability of the clip
     */
    disabled: boolean;
    /**
     * Animation properties for the clip
     */
    animations: ClipAnimationOptions;
    /**
     * Access the parent layer
     */
    layer?: Layer;
    /**
     * The input that was used to create the clip
     */
    input?: MediaInput;
    /**
     * Stores the current transition configuration; how this clip transitions to the next clip.
     */
    transition?: TransitionConfig;
    /**
     * Human readable identifier of the clip
     */
    get name(): string | undefined;
    set name(name: string);
    /**
     * Get the first visible frame
     */
    get start(): Timestamp;
    /**
     * Get the last visible frame
     */
    get stop(): Timestamp;
    /**
     * Get the delay of the clip
     */
    get delay(): Timestamp;
    /**
     * Get the duration of the clip
     */
    get duration(): Timestamp;
    constructor(props?: ClipProps);
    /**
     * Set the animation time of the clip
     * and interpolate the values
     * @param time the current absolute time to render
     */
    animate(time: Timestamp): this;
    /**
     * Method for connecting the layer with the clip
     */
    connect(layer: Layer<Clip>): Promise<void>;
    /**
     * Change clip's offset to zero in seconds. Can be negative
     */
    set delay(time: Time);
    /**
     * Set the duration of the clip, needs to be positive
     */
    set duration(time: Time);
    /**
     * Offsets the clip by a given frame number
     */
    offset(time: Time): this;
    /**
     * Triggered when the clip is
     * added to the composition
     */
    init(audio: AudioRenderer): Promise<void>;
    /**
     * Triggered when the clip enters the scene
     */
    enter(audio: AudioRenderer): Promise<void>;
    /**
     * Triggered for each redraw of the scene.
     */
    update(audio: AudioRenderer): Promise<void>;
    /**
     * Triggered after the clip was updated
     */
    render(video: VideoRenderer): void;
    /**
     * Triggered when the clip exits the scene
     */
    exit(audio: AudioRenderer): Promise<void>;
    /**
     * Seek the clip to a specific absolute time
     */
    seek(audio: AudioRenderer): Promise<void>;
    /**
     * Play the clip
     */
    play(audio: AudioRenderer): Promise<void>;
    /**
     * Pause the clip
     */
    pause(audio: AudioRenderer): Promise<void>;
    /**
     * Remove the clip from the layer
     */
    detach(): this;
    /**
     * Cleanup the clip after it has been removed from the layer
     */
    cleanup(): void;
    /**
     * Trim the clip to the specified start and stop
     */
    trim(start?: Time, stop?: Time): this;
    /**
     * Split the clip into two clips at the specified time
     * @param time split, will use the current frame of the composition
     * a fallback
     * @returns The clip that was created by performing this action
     */
    split(time?: Time): Promise<this>;
    /**
     * Create a copy of the clip. Will have receive a new id
     * but share the same source
     */
    copy(): this;
    /**
     * Create a checkpoint of the clip. May include Blob or FileSystemFileHandle.
     * @param middleware A function to modify the checkpoint data
     * @returns A serialized representation of the clip
     */
    createCheckpoint(): Promise<unknown>;
    /**
     * Restore a checkpoint of the clip.
     * @param checkpoint The checkpoint to restore
     * @param sources The sources to use for the restoration
     * @returns The restored clip
     */
    restoreCheckpoint(checkpoint: unknown, sources?: BaseSource[]): Promise<this>;
}

declare type Clip_2 = {
    start: Timestamp;
    stop: Timestamp;
    mask?: Mask;
};

declare const Clip_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent_2<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent_2<Error, any>) => void;
            } | undefined;
            offset?: {
                [x: string]: (event: EmittedEvent_2<Timestamp, any>) => void;
            } | undefined;
            frame?: {
                [x: string]: (event: EmittedEvent_2<number | undefined, any>) => void;
            } | undefined;
            attach?: {
                [x: string]: (event: EmittedEvent_2<undefined, any>) => void;
            } | undefined;
            detach?: {
                [x: string]: (event: EmittedEvent_2<undefined, any>) => void;
            } | undefined;
            update?: {
                [x: string]: (event: EmittedEvent_2<any, any>) => void;
            } | undefined;
        };
        on<T extends "*" | "error" | keyof ClipEvents>(eventType: T, callback: (event: EmittedEvent_2<BaseEvents_2<ClipEvents>[T], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T extends "*" | "error" | keyof ClipEvents>(eventType: T, detail: BaseEvents_2<ClipEvents>[T]): void;
        bubble(target: /*elided*/ any): string;
        resolve(eventType: "*" | "error" | keyof ClipEvents): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
} & typeof Serializer;

export declare type ClipAnimationOptions = KeyframeOptions<any, number | string | hex | Percent>[];

export declare class ClipDeserializer {
    static fromType(data: {
        type: ClipType;
    }): clips.Clip;
    static fromSource(data: BaseSource): clips.AudioClip | clips.HtmlClip | clips.ImageClip | undefined;
}

export declare type ClipEvents = {
    offset: Timestamp;
    frame: number | undefined;
    attach: undefined;
    detach: undefined;
    update: any;
};

export declare interface ClipProps {
    disabled?: boolean;
    name?: string;
    duration?: Time;
    delay?: Time;
    animations?: ClipAnimationOptions;
    transition?: TransitionConfig;
}

declare namespace clips {
    export {
        Clip,
        ClipType,
        ClipEvents,
        ClipAnimationOptions,
        ClipDeserializer,
        ClipProps,
        VisualMixin,
        VisualMixinAnimationOptions,
        VisualMixinProps,
        ImageClip,
        ImageClipAnimationOptions,
        ImageClipProps,
        TextClip,
        RichTextClip,
        RichTextClipProps,
        Background,
        TextClipAnimationOptions,
        TextClipProps,
        VideoClip,
        VideoClipAnimationOptions,
        VideoClipProps,
        AudioClip,
        AudioClipProps,
        SilenceRemoveOptions,
        HtmlClip,
        HtmlClipAnimationOptions,
        HtmlClipProps,
        ShapeClip,
        ShapeClipProps,
        CircleClip,
        CircleClipAnimationOptions,
        CircleClipProps,
        RectangleClip,
        RectangleClipAnimationOptions,
        RectangleClipProps,
        WaveformClip,
        WaveformBar,
        WaveformClipAnimationOptions,
        WaveformClipProps
    }
}

export declare type ClipType = 'image' | 'audio' | 'text' | 'video' | 'base' | 'html' | 'shape' | 'circle' | 'rectangle' | 'waveform';

export declare class Composition extends Composition_base {
    /**
     * Unique identifier of the composition
     */
    id: string;
    /**
     * Access the video renderer
     */
    video: VideoRenderer;
    /**
     * Access the audio renderer. Will drive the playback of the composition
     */
    audio: AudioRenderer;
    /**
     * Layers attached to the composition
     */
    layers: Layer[];
    /**
     * Behavior when playback reaches the end of the composition
     */
    playbackEndBehavior: PlaybackEndBehavior;
    /**
     * Defines special timestamps of the composition
     */
    markers: Markers;
    /**
     * Timestamp when the composition has been created
     */
    readonly createdAt: Date;
    /**
     * Data associated with the clip
     */
    data: Record<string, unknown>;
    constructor({ height, width, background, playbackEndBehavior, }?: CompositionSettings);
    /**
     * Settings of the composition
     */
    get settings(): Required<CompositionSettings>;
    set settings(settings: Required<CompositionSettings>);
    /**
     * Get the current playback state of the composition
     */
    get playing(): boolean;
    /**
     * Get the current width of the canvas
     */
    get width(): number;
    /**
     * Get the current height of the canvas
     */
    get height(): number;
    /**
     * This is where the playback stops playing
     */
    get duration(): Timestamp;
    /**
     * Limit the total duration of the composition
     */
    set duration(time: Time | undefined);
    /**
     * Get the currently rendered time of the playback
     */
    get playhead(): Timestamp;
    /**
     * Set the currently rendered time of the playback
     */
    set playhead(time: Time);
    /**
     * Get all clips in the composition
     */
    get clips(): Clip[];
    /**
     * Resize the renderer
     */
    resize(width: number, height: number): void;
    /**
     * Add the renderer to the dom.
     * This will start the ticker
     */
    mount(element: HTMLElement): void;
    /**
     * Remove the renderer from the dom.
     * This will stop the ticker
     */
    unmount(): void;
    /**
     * Insert a new layer at the specified index (defaults to 0)
     * @param Layer The layer to insert
     * @param index The index to insert at (0 = top layer, default: 0)
     */
    insertLayer<L extends Layer>(layer: L, index?: number): Promise<L>;
    /**
     * Create a layer with the given type
     * @param type the desired type of the layer
     * @returns A new layer
     */
    createLayer<L extends Clip>(index?: number): Layer<L>;
    /**
     * Create captions for the composition
     * @param source The source to create captions for
     * @param strategy The strategy to use for creating captions
     * @returns A new layer with captions
     */
    createCaptions(source: AudioClip | Transcript, strategy?: CaptionPreset | (new () => CaptionPreset)): Promise<Layer<TextClip>>;
    /**
     * Convenience function for appending a layer
     * aswell as the clip to the composition
     */
    add<L extends Clip | Clip[]>(clip: L): Promise<L>;
    /**
     * Remove a given clip from the composition
     * @returns `Clip` when it has been successfully removed `undefined` otherwise
     */
    remove<L extends Clip>(clip: L): L | undefined;
    /**
     * Compute the currently active frame
     */
    update(): Promise<void>;
    /**
     * Convenience function to take a screenshot of the current frame
     */
    screenshot(format?: ScreenshotImageFormat, quality?: number): string;
    /**
     * Set the playback position to a specific time
     * @param time new playback time (defaults to 0)
     */
    seek(time?: Time): Promise<void>;
    /**
     * Play the composition
     * @param time The time to start playing from
     */
    play(time?: Time): Promise<void>;
    /**
     * Pause the composition
     */
    pause(): Promise<void>;
    /**
     * Remove all layers and clips from the composition
     */
    clear(): void;
    /**
     * Get the current playback time and composition
     * duration formatted as `00:00 / 00:00` by default.
     * if **hours** is set the format is `HH:mm:ss` whereas
     * **milliseconds** will return `mm:ss.SSS`
     */
    time(precision?: {
        hours?: boolean;
        milliseconds?: boolean;
    }): string;
    /**
     * Remove a given layer from the composition
     * @returns `Layer` when it has been successfully removed `undefined` otherwise
     */
    removeLayer(layer: Layer): Layer | undefined;
    /**
     * Remove multiple layers from the composition
     * @returns `Layer[]` all removed layers
     */
    removeLayers(...layers: Layer[]): Layer[];
    /**
     * Handle the playback end behavior
     */
    private handlePlaybackEnd;
    /**
     * Create a checkpoint of the composition. May include Blobs.
     * @returns A serialized representation of the composition
     */
    createCheckpoint(): Promise<unknown>;
    /**
     * Restore a checkpoint of the composition.
     * @param checkpoint The checkpoint to restore
     * @param sources The sources to use for the restoration
     * @returns The restored composition
     */
    restoreCheckpoint(checkpoint: unknown, sources?: BaseSource[]): Promise<this>;
}

declare const Composition_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent<Error, any>) => void;
            } | undefined;
            play?: {
                [x: string]: (event: EmittedEvent<frame_2, any>) => void;
            } | undefined;
            pause?: {
                [x: string]: (event: EmittedEvent<frame_2, any>) => void;
            } | undefined;
            attach?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            detach?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            resize?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            mount?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            unmount?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            frame?: {
                [x: string]: (event: EmittedEvent<number | undefined, any>) => void;
            } | undefined;
            currentframe?: {
                [x: string]: (event: EmittedEvent<frame_2, any>) => void;
            } | undefined;
            init?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            update?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            load?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
        };
        on<T extends "*" | "error" | keyof CompositionEvents>(eventType: T, callback: (event: EmittedEvent<BaseEvents<CompositionEvents>[T], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T extends "*" | "error" | keyof CompositionEvents>(eventType: T, detail: BaseEvents<CompositionEvents>[T]): void;
        bubble(target: /*elided*/ any): string;
        resolve(eventType: "*" | "error" | keyof CompositionEvents): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
} & typeof Serializer;

/**
 * Defines the type of events emitted by the
 * composition
 */
export declare type CompositionEvents = {
    play: frame;
    pause: frame;
    attach: undefined;
    detach: undefined;
    resize: undefined;
    mount: undefined;
    unmount: undefined;
    frame: number | undefined;
    currentframe: frame;
    init: undefined;
    update: any;
    load: undefined;
};

export declare type CompositionSettings = {
    /**
     * Height of the composition
     *
     * @default 1080
     */
    height?: int;
    /**
     * Width of the composition
     *
     * @default 1920
     */
    width?: int;
    /**
     * Background color of the composition
     *
     * @default #000000
     */
    background?: hex | 'transparent';
    /**
     * Behavior when playback reaches the end of the composition
     * - 'stop': Pause at the end
     * - 'loop': Continue playing from the beginning
     * - 'reset': Jump to frame 0 and pause
     *
     * @default 'stop'
     */
    playbackEndBehavior?: PlaybackEndBehavior;
};

/**
 * Defines the constructor required by mixins
 */
export declare type Constructor<T = {}> = new (...args: any[]) => T;

declare type ContainerFormat = 'mp4' | 'webm' | 'ogg';

export declare const DateDeserializer: {
    fromJSON: (date: string) => Date;
};

/**
 * Limit the number of times a function can be called
 * per interval, timeout is in milliseconds
 */
export declare function debounce(func: Function, timeout?: number): (...args: any[]) => void;

export declare class DecoderError extends BaseError {
}

export declare interface DefaultCaptionPresetConfig extends CaptionPresetConfig {
    generatorOptions?: GeneratorOptions;
}

export declare type Deserializer<T> = (data: any) => Promise<T> | T;

declare interface Deserializer_2 {
    fromJSON?: (obj: any) => any;
}

export declare function detectContentType(input: MediaInput): Promise<string>;

/**
 * This utility creates an anchor tag and clicks on it
 * @param source Blob url or base64 encoded svg
 * @param name File name suggestion
 */
export declare function downloadObject(source: MediaInput, name?: string): Promise<void>;

/**
 * An optional easing function to apply to the interpolation.
 * Easing functions can modify the interpolation to be non-linear.
 * @default "linear"
 */
export declare type Easing = 'linear' | 'ease-in' | 'ease-out' | 'ease-in-out' | 'ease-out-in';

/**
 * Defines a circle with a width and height
 */
export declare interface Ellipse {
    /**
     * The x coordinate of the ellipse
     */
    cx: number | Percent;
    /**
     * The y coordinate of the ellipse
     */
    cy: number | Percent;
    /**
     * The width of the ellipse
     */
    width: number | Percent;
    /**
     * The height of the ellipse
     */
    height: number | Percent;
}

declare type EmittedEvent_3<K, T extends {}> = OverrideValues<CustomEvent<K>, {
    target: T;
}>;

export declare type EncodedOpusChunk = {
    data: Uint8Array;
    timestamp: number;
    type: 'key' | 'delta';
    duration: number;
};

export declare type EncodedOpusChunkOutputCallback = (output: EncodedOpusChunk, metadata: EncodedAudioChunkMetadata) => void;

export declare class Encoder extends Encoder_base {
    private composition;
    private config;
    /**
     * Create a new audio and video encoder and multiplex the result
     * using a mp4 container
     * @param composition The composition to render
     * @param config Configure the output
     * @example
     * ```
     * const blob = await new Encoder(composition).render();
     * ```
     */
    constructor(composition: Composition, config?: EncoderConfig);
    /**
     * Export the specified composition
     * @throws DOMException if the export has been aborted
     */
    render(target?: WriteStreamCallback | FileSystemFileHandle | WritableStream | string, signal?: AbortSignal): Promise<undefined | Blob>;
    audioCodecs(): Promise<("opus" | "aac" | "mp3" | "vorbis" | "flac" | "pcm-s16" | "pcm-s16be" | "pcm-s24" | "pcm-s24be" | "pcm-s32" | "pcm-s32be" | "pcm-f32" | "pcm-f32be" | "pcm-u8" | "pcm-s8" | "ulaw" | "alaw")[]>;
    videoCodecs(): Promise<("avc" | "hevc" | "vp9" | "av1" | "vp8")[]>;
    private log;
}

declare const Encoder_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent<Error, any>) => void;
            } | undefined;
            render?: {
                [x: string]: (event: EmittedEvent<    {
                progress: number;
                total: number;
                remaining: Date;
                }, any>) => void;
            } | undefined;
        };
        on<T extends "*" | "error" | "render">(eventType: T, callback: (event: EmittedEvent<BaseEvents<EncoderEvents>[T], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T extends "*" | "error" | "render">(eventType: T, detail: BaseEvents<EncoderEvents>[T]): void;
        bubble(target: {
            _handlers: {
                '*'?: {
                    [x: string]: (event: EmittedEvent<any, any>) => void;
                } | undefined;
                error?: {
                    [x: string]: (event: EmittedEvent<Error, any>) => void;
                } | undefined;
                render?: {
                    [x: string]: (event: EmittedEvent<    {
                    progress: number;
                    total: number;
                    remaining: Date;
                    }, any>) => void;
                } | undefined;
            };
            on<T extends "*" | "error" | "render">(eventType: T, callback: (event: EmittedEvent<BaseEvents<EncoderEvents>[T], /*elided*/ any>) => void): string;
            off(id?: string | "*", ...ids: string[]): void;
            emit<T extends "*" | "error" | "render">(eventType: T, detail: BaseEvents<EncoderEvents>[T]): void;
            bubble(target: /*elided*/ any): string;
            resolve(eventType: "*" | "error" | "render"): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
        }): string;
        resolve(eventType: "*" | "error" | "render"): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
};

declare interface EncoderConfig {
    /**
     * Video encoding configuration
     */
    video?: VideoConfig;
    /**
     * Audio encoding configuration
     */
    audio?: AudioConfig;
    /**
     * Defines if the performance should be logged
     * @default false
     */
    debug?: boolean;
    /**
     * Defines the watermark to add to the video.
     * Needs to be more than 5 characters long
     */
    watermark?: string;
    /**
     * Defines the output format of the encoded file
     * @default 'mp4'
     */
    format?: ContainerFormat;
}

export declare class EncoderError extends BaseError {
}

declare type EncoderEvents = {
    render: {
        /**
         * Defines how many frames were rendered yet
         */
        progress: number;
        /**
         * Defines the total number of frames
         * to be rendered
         */
        total: number;
        /**
         * Defines the estimated remaining
         * render time
         */
        remaining: Date;
    };
};

/**
 * Error message structure
 */
export declare type ErrorEventDetail = {
    msg: string;
    code: string;
    params?: any;
};

export declare function EventEmitter<Events = {}>(): {
    new (...args: any[]): {
        _handlers: { [T in keyof BaseEvents<Events>]?: {
                [x: string]: (event: EmittedEvent<BaseEvents<Events>[T], any>) => void;
            } | undefined; };
        on<T_1 extends "*" | "error" | keyof Events>(eventType: T_1, callback: (event: EmittedEvent<BaseEvents<Events>[T_1], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T_1 extends "*" | "error" | keyof Events>(eventType: T_1, detail: BaseEvents<Events>[T_1]): void;
        bubble(target: {
            _handlers: { [T in keyof BaseEvents<Events>]?: {
                    [x: string]: (event: EmittedEvent<BaseEvents<Events>[T], any>) => void;
                } | undefined; };
            on<T_1 extends "*" | "error" | keyof Events>(eventType: T_1, callback: (event: EmittedEvent<BaseEvents<Events>[T_1], /*elided*/ any>) => void): string;
            off(id?: string | "*", ...ids: string[]): void;
            emit<T_1 extends "*" | "error" | keyof Events>(eventType: T_1, detail: BaseEvents<Events>[T_1]): void;
            bubble(target: /*elided*/ any): string;
            resolve(eventType: "*" | "error" | keyof Events): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
        }): string;
        resolve(eventType: "*" | "error" | keyof Events): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
};

export declare function EventEmitterMixin<Events = {}, T extends Constructor = Constructor>(Base: T): {
    new (...args: any[]): {
        _handlers: { [T_1 in keyof BaseEvents_3<Events>]?: {
                [x: string]: (event: EmittedEvent_3<BaseEvents_3<Events>[T_1], any>) => void;
            }; };
        on<T_1 extends keyof BaseEvents_3<Events>>(eventType: T_1, callback: (event: EmittedEvent_3<BaseEvents_3<Events>[T_1], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T_1 extends keyof BaseEvents_3<Events>>(eventType: T_1, detail: BaseEvents_3<Events>[T_1]): void;
        bubble(target: /*elided*/ any): string;
        resolve(eventType: keyof BaseEvents_3<Events>): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
} & T;

declare type Events = {
    frame: number | undefined;
    attach: undefined;
    detach: undefined;
    update: any;
};

declare type Events_2 = {
    update: any;
};

/**
 * Defines the extrapolation behavior outside the input range.
 * - "clamp": Clamps the value to the nearest endpoint within the range.
 * - "extend": Allows values to extend beyond the range.
 * @default "clamp"
 */
export declare type Extrapolate = 'clamp' | 'extend';

/**
 * Defines the fill properties that
 * can be applied to a shape
 */
export declare interface FillOptions {
    /**
     * The color of the fill
     */
    color: hex | Gradient | Pattern;
    /**
     * The opacity of the fill
     */
    opacity?: number;
}

/**
 * Defines the fill rule of the mask
 */
export declare type FillRule = 'nonzero' | 'evenodd';

/**
 * Defines a floating point number
 */
export declare type float = (number & {
    _float: void;
}) | number;

/**
 * Converts a Float32Array to 16-bit PCM.
 */
export declare function floatTo16BitPCM(dataview: DataView, buffer: Float32Array, offset: number): DataView;

/**
 * Defines the properties of a font
 */
export declare interface Font {
    /**
     * The size of the font
     */
    size: number;
    /**
     * The family of the font
     */
    family: string;
    /**
     * The weight of the font
     */
    weight?: FontWeight;
    /**
     * The style of the font
     */
    style?: FontStyle;
}

export declare const FONT_WEIGHTS: {
    readonly '100': "Thin";
    readonly '200': "Extra Light";
    readonly '300': "Light";
    readonly '400': "Normal";
    readonly '500': "Medium";
    readonly '600': "Semi Bold";
    readonly '700': "Bold";
    readonly '800': "Extra Bold";
    readonly '900': "Black";
};

/**
 * Defines all available font families
 */
export declare type FontFamily = keyof typeof WebFonts | string;

export declare class FontManager extends Serializer {
    /**
     * The fonts that have been loaded
     */
    loadedFonts: types.FontSource[];
    /**
     * Load the font that has been initiated via the constructor
     */
    load<T extends keyof typeof WebFonts>(options: types.FontSource | types.WebfontProperties<T>): Promise<Font>;
    /**
     * Reload all fonts
     * @deprecated Use restoreCheckpoint instead
     */
    reload(): Promise<void>;
    /**
     * Get all available local fonts, requires the
     * **Local Font Access API**
     */
    static localFonts(): Promise<types.FontSources[]>;
    /**
     * Get common web fonts
     */
    static webFonts(): types.FontSources[];
    static load<T extends keyof typeof WebFonts>(options: types.FontSource | types.WebfontProperties<T>): Promise<Font>;
    copy(): FontManager;
    /**
     * Create a checkpoint of the current font manager state
     */
    createCheckpoint(): Promise<unknown>;
    /**
     * Restore the font manager state from a checkpoint
     * @param checkpoint - The checkpoint to restore from
     */
    restoreCheckpoint(checkpoint: unknown): Promise<void>;
}

/**
 * Defines the properties that are required
 * to load a new font
 */
export declare type FontSource = {
    /**
     * Name of the Family
     * @example 'Arial'
     */
    family: string;
    /**
     * Source of the Variant
     * @example url(arial.ttf)
     */
    source: string;
    /**
     * Defines the font style
     * @example 'italic'
     */
    style?: FontStyle;
    /**
     * The weight of the font
     * @example '400'
     */
    weight?: FontWeight;
    /**
     * The size of the font
     * @example 16
     */
    size?: number;
};

/**
 * Defines a single font that has one or
 * more variants
 */
export declare type FontSources = {
    family: string;
    variants: FontSource[];
};

/**
 * Defines the style of the font
 */
export declare type FontStyle = 'normal' | 'italic' | 'oblique';

/**
 * Defines all available font subsets which
 * limit the number of characters
 */
export declare type FontSubset = 'latin' | 'latin-ext' | 'vietnamese' | 'cyrillic' | 'cyrillic-ext';

/**
 * Defines the source where the font is coming from
 */
export declare type FontType = 'local' | 'web';

/**
 * Defines the thickness/weight of the font
 */
export declare type FontWeight = 'normal' | 'bold' | '100' | '200' | '300' | '400' | '500' | '600' | '700' | '800' | '900';

export declare const FPS_DEFAULT = 30;

export declare const FPS_INACTIVE = 1;

/**
 * Defines an interger that correspondes
 * to a point in time
 */
export declare type frame = (number & {
    _frame: void;
}) | number;

/**
 * Convert frames to milliseconds
 */
export declare function framesToMillis(frames: frame, fps?: number): number;

/**
 * Convert frames into seconds
 */
export declare function framesToSeconds(frames: frame, fps?: number): number;

export declare type GeneratorOptions = {
    /**
     * Iterates by word count
     */
    count?: [number, number?];
    /**
     * Iterates by group duration
     */
    duration?: [number, number?];
    /**
     * Iterates by number of characters within the group
     */
    length?: [number, number?];
};

/**
 * Function for retrieving the best supported avc profile
 * @param settings - Video settings
 * @returns Supported avc profile
 */
export declare function getBestSupportedAvcProfile(settings: VideoSettings): Promise<string | undefined>;

/**
 * Defines the properties of a glow
 */
export declare interface Glow {
    /**
     * The color of the glow
     */
    color?: hex;
    /**
     * The radius of the glow
     */
    radius?: number;
    /**
     * The intensity of the glow
     */
    intensity?: number;
    /**
     * The opacity of the glow
     */
    opacity?: number;
}

/**
 * Defines the properties of a gradient
 */
export declare interface Gradient {
    /**
     * The type of gradient to use
     */
    type: GradientType;
    /**
     * The stops of the gradient
     */
    stops: GradientStop[];
}

/**
 * Defines the properties of a gradient stop
 */
export declare interface GradientStop {
    /**
     * The offset of the gradient stop
     */
    offset: number;
    /**
     * The color of the gradient stop
     */
    color: string;
}

/**
 * Defines the type of gradient to use
 */
export declare type GradientType = 'linear' | 'radial';

/**
 * Group an array of objects by the specified key
 */
export declare function groupBy<T extends {}, K extends keyof T>(arr: T[], key: K): Record<T[K], T[]>;

export declare class GuineaCaptionPreset extends CaptionPreset {
    colors: hex[];
    constructor(config?: MultiColorCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
    protected splitSequence(sequence: WordGroup): {
        segments: string[];
        words: Word[][];
    };
}

/**
 * Defines a color hex value
 */
export declare type hex = `#${string}`;

export declare function hexWithOpacity(color?: hex, opacity?: number): hex;

export declare type HSL = {
    h: number;
    s: number;
    l: number;
};

export declare class HtmlClip extends HtmlClip_base {
    _keepAspectRatio: boolean;
    readonly type = "html";
    layer?: Layer<HtmlClip>;
    source: HtmlSource;
    animations: HtmlClipAnimationOptions;
    /**
     * Access to the html document that
     * will be rendered to the canvas
     */
    readonly element: HTMLImageElement;
    constructor(input?: MediaInput | HtmlSource, props?: HtmlClipProps);
    init(): Promise<void>;
    render(renderer: VideoRenderer): void;
    refresh(): this;
}

declare const HtmlClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent_2;
        _width?: number | Percent_2;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent_2;
        y: number | Percent_2;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent_2;
        set height(value: Percent_2 | number | undefined);
        get width(): number | Percent_2;
        set width(value: Percent_2 | number | undefined);
        get position(): RelativePoint_2;
        set position(value: RelativePoint_2 | "center");
        animate(time: Timestamp_2): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp_2;
        stop: Timestamp_2;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof Clip;

export declare type HtmlClipAnimationOptions = VisualMixinAnimationOptions;

export declare interface HtmlClipProps extends ClipProps, VisualMixinProps {
    animations?: HtmlClipAnimationOptions;
}

export declare class HtmlSource extends HtmlSource_base {
    readonly type: ClipType;
    element: HTMLIFrameElement;
    constructor(options: SourceOptions);
    init(): Promise<void>;
    /**
     * Access to the html document as loaded
     * within the iframe. Can be manipulated with
     * javascript
     */
    get document(): Document | undefined;
    get imageUrl(): string;
    thumbnail(): Promise<HTMLImageElement>;
}

declare const HtmlSource_base: {
    new (...args: any[]): {
        height: int_2;
        width: int_2;
        readonly aspectRatio: number;
        id: string;
        data: Record<string, unknown>;
        readonly type: ClipType;
        mimeType: string;
        input: MediaInput_2;
        name: string;
        createdAt: Date;
        init(options?: SourceInitOptions_2): Promise<void>;
        arrayBuffer(): Promise<ArrayBuffer>;
        download(): Promise<void>;
        thumbnail(): Promise<HTMLElement>;
        createCheckpoint(): Promise<unknown>;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof BaseSource;

export declare class ImageClip extends ImageClip_base {
    _keepAspectRatio: boolean;
    readonly type = "image";
    layer?: Layer<ImageClip>;
    source?: ImageSource;
    animations: ImageClipAnimationOptions;
    constructor(input?: MediaInput | ImageSource, props?: ImageClipProps);
    init(): Promise<void>;
    render(renderer: VideoRenderer): void;
}

declare const ImageClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent_2;
        _width?: number | Percent_2;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent_2;
        y: number | Percent_2;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent_2;
        set height(value: Percent_2 | number | undefined);
        get width(): number | Percent_2;
        set width(value: Percent_2 | number | undefined);
        get position(): RelativePoint_2;
        set position(value: RelativePoint_2 | "center");
        animate(time: Timestamp_2): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp_2;
        stop: Timestamp_2;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof Clip;

export declare type ImageClipAnimationOptions = VisualMixinAnimationOptions;

export declare interface ImageClipProps extends ClipProps, VisualMixinProps {
    animations?: ImageClipAnimationOptions;
}

/**
 * Defines the properties of an image
 */
export declare interface ImageOptions {
    /**
     * The x coordinate of the image
     */
    x?: number | Percent;
    /**
     * The y coordinate of the image
     */
    y?: number | Percent;
    /**
     * The width of the image
     */
    width: number | Percent;
    /**
     * The height of the image
     */
    height: number | Percent;
    /**
     * The rotation of the image in degrees
     */
    rotation?: number;
}

export declare class ImageSource extends ImageSource_base {
    readonly type: ClipType;
    element: HTMLImageElement;
    init(): Promise<void>;
    thumbnail(): Promise<HTMLImageElement>;
}

declare const ImageSource_base: {
    new (...args: any[]): {
        height: int_2;
        width: int_2;
        readonly aspectRatio: number;
        id: string;
        data: Record<string, unknown>;
        readonly type: ClipType;
        mimeType: string;
        input: MediaInput_2;
        name: string;
        createdAt: Date;
        init(options?: SourceInitOptions_2): Promise<void>;
        arrayBuffer(): Promise<ArrayBuffer>;
        download(): Promise<void>;
        thumbnail(): Promise<HTMLElement>;
        createCheckpoint(): Promise<unknown>;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof BaseSource;

/**
 * Represents an input media file. This is the root object from which all media read operations start.
 * @public
 */
declare class Input<S extends Source_2 = Source_2> {
    constructor(options: InputOptions<S>);
    /**
     * Returns the source from which this input file reads its data. This is the same source that was passed to the
     * constructor.
     */
    get source(): S;
    /**
     * Returns the format of the input file. You can compare this result directly to the InputFormat singletons or use
     * `instanceof` checks for subset-aware logic (for example, `format instanceof MatroskaInputFormat` is true for
     * both MKV and WebM).
     */
    getFormat(): Promise<InputFormat>;
    /**
     * Computes the duration of the longest track in this input file, in seconds. More precisely, returns the largest
     * end timestamp among all tracks.
     */
    computeDuration(): Promise<number>;
    /** Returns the list of all tracks of this input file. */
    getTracks(): Promise<InputTrack[]>;
    /** Returns the list of all video tracks of this input file. */
    getVideoTracks(): Promise<InputVideoTrack[]>;
    /** Returns the primary video track of this input file, or null if there are no video tracks. */
    getPrimaryVideoTrack(): Promise<InputVideoTrack | null>;
    /** Returns the list of all audio tracks of this input file. */
    getAudioTracks(): Promise<InputAudioTrack[]>;
    /** Returns the primary audio track of this input file, or null if there are no audio tracks. */
    getPrimaryAudioTrack(): Promise<InputAudioTrack | null>;
    /** Returns the full MIME type of this input file, including track codecs. */
    getMimeType(): Promise<string>;
}

/**
 * Represents an audio track in an input file.
 * @public
 */
declare class InputAudioTrack extends InputTrack {
    get type(): TrackType;
    get codec(): AudioCodec | null;
    /** The number of audio channels in the track. */
    get numberOfChannels(): number;
    /** The track's audio sample rate in hertz. */
    get sampleRate(): number;
    /** Returns the decoder configuration for decoding the track's packets using an AudioDecoder. */
    getDecoderConfig(): Promise<AudioDecoderConfig | null>;
    getCodecParameterString(): Promise<string | null>;
    canDecode(): Promise<boolean>;
}

/**
 * Base class representing an input media file format.
 * @public
 */
declare abstract class InputFormat {
    /** Returns the name of the input format. */
    abstract getName(): string;
    /** Returns the typical base MIME type of the input format. */
    abstract getMimeType(): string;
}

/**
 * The options for creating an Input object.
 * @public
 */
declare type InputOptions<S extends Source_2 = Source_2> = {
    /** A list of supported formats. If the source file is not of one of these formats, then it cannot be read. */
    formats: InputFormat[];
    /** The source from which data will be read. */
    source: S;
};

/**
 * Represents a media track in an input file.
 * @public
 */
declare abstract class InputTrack {
    /** The type of the track. */
    abstract get type(): TrackType;
    /** The codec of the track's packets. */
    abstract get codec(): MediaCodec | null;
    /** Returns the full codec parameter string for this track. */
    abstract getCodecParameterString(): Promise<string | null>;
    /** Checks if this track's packets can be decoded by the browser. */
    abstract canDecode(): Promise<boolean>;
    /** Returns true iff this track is a video track. */
    isVideoTrack(): this is InputVideoTrack;
    /** Returns true iff this track is an audio track. */
    isAudioTrack(): this is InputAudioTrack;
    /** The unique ID of this track in the input file. */
    get id(): number;
    /** The ISO 639-2/T language code for this track. If the language is unknown, this field is 'und' (undetermined). */
    get languageCode(): string;
    /**
     * A positive number x such that all timestamps and durations of all packets of this track are
     * integer multiples of 1/x.
     */
    get timeResolution(): number;
    /**
     * Returns the start timestamp of the first packet of this track, in seconds. While often near zero, this value
     * may be positive or even negative. A negative starting timestamp means the track's timing has been offset. Samples
     * with a negative timestamp should not be presented.
     */
    getFirstTimestamp(): Promise<number>;
    /** Returns the end timestamp of the last packet of this track, in seconds. */
    computeDuration(): Promise<number>;
    /** Computes aggregate packet statistics for this track, such as average packet rate or bitrate. */
    computePacketStats(): Promise<PacketStats>;
}

/**
 * Represents a video track in an input file.
 * @public
 */
declare class InputVideoTrack extends InputTrack {
    get type(): TrackType;
    get codec(): "avc" | "hevc" | "vp9" | "av1" | "vp8" | null;
    /** The width in pixels of the track's coded samples, before any transformations or rotations. */
    get codedWidth(): number;
    /** The height in pixels of the track's coded samples, before any transformations or rotations. */
    get codedHeight(): number;
    /** The angle in degrees by which the track's frames should be rotated (clockwise). */
    get rotation(): Rotation;
    /** The width in pixels of the track's frames after rotation. */
    get displayWidth(): number;
    /** The height in pixels of the track's frames after rotation. */
    get displayHeight(): number;
    /** Returns the color space of the track's samples. */
    getColorSpace(): Promise<VideoColorSpaceInit>;
    /** If this method returns true, the track's samples use a high dynamic range (HDR). */
    hasHighDynamicRange(): Promise<boolean>;
    /** Returns the decoder configuration for decoding the track's packets using a VideoDecoder. */
    getDecoderConfig(): Promise<VideoDecoderConfig | null>;
    getCodecParameterString(): Promise<string | null>;
    canDecode(): Promise<boolean>;
}

export declare type InsertMode = (typeof insertModes)[number];

declare const insertModes: readonly ["DEFAULT", "SEQUENTIAL"];

declare interface InsertStrategy<T extends InsertMode> extends Omit<Serializer, 'fromJSON'> {
    readonly mode: T;
    add(clip: Clip, layer: Layer, index?: number): void;
    update(clip: Clip, layer: Layer): void;
    offset(time: Timestamp, layer: Layer): void;
}

/**
 * Defines a number without decimal places
 */
export declare type int = (number & {
    _int: void;
}) | number;

/**
 * Converts an AudioBuffer to a Float32Array.
 * For 2 channels it will result in something like:
 * [L[0], R[0], L[1], R[1], ... , L[n], R[n]]
 */
export declare function interleave(input: AudioBuffer): Float32Array;

export declare class IOError extends BaseError {
}

export declare interface KeyFrame<T> {
    value: T;
    time: Time;
    easing?: Easing;
}

export declare interface KeyframeOptions<K, T> {
    key: K;
    extrapolate?: Extrapolate;
    frames: KeyFrame<T>[];
    easing?: Easing;
}

export declare enum Language {
    en = "en",
    de = "de"
}

export declare class Layer<Clp extends Clip = Clip> extends Layer_base {
    /**
     * Unique identifier of the object
     */
    id: string;
    /**
     * Data associated with the layer
     */
    data: Record<string, unknown>;
    /**
     * Flag to check if the layer is the primary layer
     */
    primary: boolean;
    /**
     * Controls the visability of the layer
     */
    disabled: boolean;
    /**
     * The clips to be displayed
     */
    clips: Clp[];
    /**
     * Reference to the composition
     */
    composition?: Composition;
    /**
     * Controls how the clips should be inserted and updated
     */
    strategy: InsertStrategy<InsertMode>;
    /**
     * Timestamp when the layer has been created
     */
    readonly createdAt: Date;
    /**
     * Id of the clips in the layer
     */
    get type(): ClipType;
    /**
     * The index of the clip that should be rendered
     */
    private currentMainClipIndex;
    /**
     * Tracks the clips that are currently visible. In the case of transitions, this can be more than one clip at a time.
     */
    private visibleClips;
    /**
     * Connect the layer with the composition
     */
    connect(composition: Composition): this | Promise<this>;
    /**
     * Applies the stack property
     */
    sequential(value?: boolean): this;
    /**
     * Change the index of the layer
     */
    index(layer: LayerIndex): this;
    /**
     * Seek the provided time if the layer contains
     * audio or video clips. Will await the promise
     * otherwise will resolve immediately
     */
    seek(audio: AudioRenderer): Promise<void>;
    /**
     * Seek the provided time if the layer contains
     * audio or video clips. Will await the promise
     * otherwise will resolve immediately
     */
    play(audio: AudioRenderer): Promise<void>;
    /**
     * Seek the provided time if the layer contains
     * audio or video clips. Will await the promise
     * otherwise will resolve immediately
     */
    pause(audio: AudioRenderer): Promise<void>;
    /**
     * Move all clips of the layer at once along the timeline
     */
    offset(time: Time): this;
    /**
     * Triggered when the layer is redrawn, manages
     * the clip's lifecycle
     */
    update(audio: AudioRenderer): Promise<void>;
    render(audio: AudioRenderer, video: VideoRenderer): void;
    /**
     * Adds a new clip to the layer. Calls update after adding the clip.
     * @param clip The clip to add
     * @param index The index to insert the clip at, will be ignored if layer is not stacked
     * @throws Error if the clip can't be added
     */
    add<L extends Clp>(clip: L, index?: number): Promise<L>;
    /**
     * Remove a given clip from the layer. Calls update after removing the clip.
     * @returns `Layer` when it has been successfully removed `undefined` otherwise
     */
    remove<L extends Clp>(clip: L): L | undefined;
    /**
     * Get the first visible frame of the clip
     */
    get stop(): Timestamp;
    /**
     * Get the last visible frame of the clip
     */
    get start(): Timestamp;
    /**
     * Remove the layer from the composition
     */
    detach(): this;
    /**
     * Remove all clips from the layer
     */
    clear(): void;
    _resetInternalState(): void;
    /**
     * Create a checkpoint of the layer. May include Blobs.
     * @returns A serialized representation of the layer
     */
    createCheckpoint(): Promise<unknown>;
    /**
     * Restore a checkpoint of the layer.
     * @param checkpoint The checkpoint to restore
     * @param sources The sources to use for the restoration
     * @returns The restored layer
     */
    restoreCheckpoint(checkpoint: unknown, sources?: BaseSource[]): Promise<this>;
}

declare const Layer_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent<Error, any>) => void;
            } | undefined;
            frame?: {
                [x: string]: (event: EmittedEvent<number | undefined, any>) => void;
            } | undefined;
            attach?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            detach?: {
                [x: string]: (event: EmittedEvent<undefined, any>) => void;
            } | undefined;
            update?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
        };
        on<T extends "*" | "error" | keyof Events>(eventType: T, callback: (event: EmittedEvent<BaseEvents<Events>[T], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T extends "*" | "error" | keyof Events>(eventType: T, detail: BaseEvents<Events>[T]): void;
        bubble(target: /*elided*/ any): string;
        resolve(eventType: "*" | "error" | keyof Events): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
} & typeof Serializer;

/**
 * Defines where the layer should be inserted
 */
export declare type LayerIndex = 'top' | 'bottom' | number;

/**
 * Defines the cap style of the stroke
 */
export declare type LineCap = 'butt' | 'round' | 'square';

/**
 * Defines the join style of the stroke
 */
export declare type LineJoin = 'bevel' | 'round' | 'miter';

/**
 * Defines the type of markers that can be set on the composition
 */
export declare type Markers = Record<string | 'start', Timestamp>;

export declare class Mask extends Serializer {
    /**
     * Unique identifier of the mask
     */
    id: string;
    readonly type: MaskType;
    width: number | Percent;
    height: number | Percent;
    fillRule?: FillRule;
    animations: KeyframeOptions<any, number | Percent>[];
    clip?: Clip_2;
    protected renderer?: VideoRenderer;
    constructor({ width, height }?: MaskProps);
    connect(clip: Clip_2): this;
    draw(renderer: VideoRenderer): Path2D;
    animate(time: Timestamp): this;
    get start(): Timestamp;
    get stop(): Timestamp;
    get size(): Size;
    get bounds(): [Point, Point, Point, Point];
    detach(): this;
}

export declare class MaskDeserializer {
    static fromJSON<T extends Mask>(object: unknown): T;
}

export declare interface MaskProps {
    width?: number | Percent;
    height?: number | Percent;
}

export declare type MaskType = 'rectangle' | 'circle' | 'base';

/**
 * Union type of known media codecs.
 * @public
 */
declare type MediaCodec = VideoCodec | AudioCodec | SubtitleCodec;

/**
 * Defines the asset source, e.g. a file, blob or url
 */
export declare type MediaInput = File | Blob | string | FileSystemFileHandle;

export declare type MixinType<T extends (...args: any[]) => {
    new (...args: any[]): any;
}> = InstanceType<ReturnType<T>>;

export declare interface MultiColorCaptionPresetConfig extends DefaultCaptionPresetConfig {
    colors?: hex[];
}

export declare class OpusEncoder {
    output: EncodedOpusChunkOutputCallback;
    error: WebCodecsErrorCallback;
    config?: OpusEncoderConfig_2;
    private encoder?;
    private opus?;
    private meta?;
    /**
     * Create a new OpusEncoder for encoding pcm to opus
     * @param init encoder callbacks
     */
    constructor(init: OpusEncoderInit);
    /**
     * Configure the encoder. **Note** these values must match the samples to encode
     * @param config The sample rate and channel count to use
     */
    configure(config: OpusEncoderConfig_2): Promise<void>;
    /**
     * Encode the samples synchronously (this is a blocking event)
     * @param samples The data to encode
     */
    encode({ data, numberOfFrames, timestamp }: OpusEncoderSamples): void;
}

declare type OpusEncoderConfig_2 = Omit<AudioEncoderConfig, 'codec' | 'bitrate'>;
export { OpusEncoderConfig_2 as OpusEncoderConfig }

export declare type OpusEncoderInit = {
    output: EncodedOpusChunkOutputCallback;
    error: WebCodecsErrorCallback;
};

export declare type OpusEncoderSamples = {
    /**
     * 16-bit signed integer array of interleaved audio samples
     */
    data: Int16Array;
    /**
     * The number of frames (usually total samples / number of channels)
     */
    numberOfFrames: number;
    /**
     * Defines the timestamp of the first frame
     */
    timestamp?: number;
};

declare type OverrideValues<T, U> = Omit<T, keyof U> & Pick<U, Extract<keyof U, keyof T>>;

/**
 * Contains aggregate statistics about the encoded packets of a track.
 * @public
 */
declare type PacketStats = {
    /** The total number of packets. */
    packetCount: number;
    /** The average number of packets per second. For video tracks, this will equal the average frame rate (FPS). */
    averagePacketRate: number;
    /** The average number of bits per second. */
    averageBitrate: number;
};

export declare class PaperCaptionPreset extends CaptionPreset {
    constructor(config?: DefaultCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
    protected splitSequence(sequence: WordGroup): {
        segments: string[];
        words: Word[][];
    };
}

/**
 * Converts various time formats to a Timestamp
 * @param time Time in various formats (ms, s, f (frames), min, MM:SS, HH:MM:SS, number (frames), or Timestamp)
 * @param fps Optional frames per second for frame calculations (default: 60)
 * @returns Timestamp
 */
export declare function parseTime(time?: Time): Timestamp;

/**
 * Defines the properties of a pattern
 */
export declare interface Pattern {
    /**
     * The image to use for the pattern
     */
    image: HTMLImageElement | HTMLCanvasElement;
    /**
     * The repetition of the pattern
     */
    repetition: PatternRepetition;
}

/**
 * Defines the repetition of the pattern
 */
export declare type PatternRepetition = 'repeat' | 'repeat-x' | 'repeat-y' | 'no-repeat';

/**
 * Defines a string that starts with a number
 * and ends with a `%` character
 * @example '50%'
 */
export declare type Percent = `${number}%` | `${number}.${number}%`;

/**
 * Defines how the composition behaves when playback reaches the end
 */
export declare type PlaybackEndBehavior = 'stop' | 'loop' | 'reset';

/**
 * Defines the properties of a point
 */
export declare interface Point {
    /**
     * The x coordinate of the point
     */
    x: number;
    /**
     * The y coordinate of the point
     */
    y: number;
}

/**
 * Generate a random value between two numbers
 */
export declare function randInt(min: number, max: number | undefined): number;

/**
 * Defines the properties of a rectangle
 */
export declare interface Rect extends Partial<Point> {
    /**
     * The width of the rectangle
     */
    width: number | Percent;
    /**
     * The height of the rectangle
     */
    height: number | Percent;
}

export declare class RectangleClip extends ShapeClip {
    readonly type = "rectangle";
    layer?: Layer<RectangleClip>;
    animations: RectangleClipAnimationOptions;
    radius?: number | Percent;
    constructor(props?: RectangleClipProps);
    get name(): string;
    /**
     * Access to the html document that
     * will be rendered to the canvas
     */
    render(renderer: VideoRenderer): void;
}

export declare type RectangleClipAnimationOptions = (KeyframeOptions<'x' | 'y' | 'height' | 'width' | 'translateX' | 'translateY' | 'radius', number | Percent> | KeyframeOptions<'opacity' | 'rotation' | 'scale' | 'scaleX' | 'scaleY', number> | KeyframeOptions<'fill', string>)[];

export declare interface RectangleClipProps extends ShapeClipProps {
    radius?: number | Percent;
    animations?: RectangleClipAnimationOptions;
}

export declare class RectangleMask extends Mask {
    readonly type: MaskType;
    x: number | Percent;
    y: number | Percent;
    radius: number | Percent;
    constructor({ x, y, radius, animations, ...props }?: RectangleMaskProps);
    draw(renderer: VideoRenderer): Path2D;
    get bounds(): [Point, Point, Point, Point];
}

export declare type RectangleMaskAnimationOptions = KeyframeOptions<'x' | 'y' | 'radius' | 'width' | 'height', number | Percent>[];

export declare interface RectangleMaskProps extends MaskProps {
    x?: number | Percent;
    y?: number | Percent;
    radius?: number | Percent;
    animations?: RectangleMaskAnimationOptions;
}

declare class ReferenceError_2 extends BaseError {
}
export { ReferenceError_2 as ReferenceError }

export declare interface RelativePoint {
    /**
     * The x coordinate of the point
     */
    x: number | Percent;
    /**
     * The y coordinate of the point
     */
    y: number | Percent;
}

/**
 * Defines the render mode of the composition
 */
export declare type RenderMode = 'pause' | 'play' | 'render';

/**
 * Change the sample rate of an audio buffer
 * @param buffer The buffer to resample
 * @param sampleRate The desired sample rate
 * @param numberOfChannels The desired number of channels
 * @returns The resampled audio buffer
 */
export declare function resampleBuffer(buffer: AudioBuffer, sampleRate?: number, numberOfChannels?: number): AudioBuffer;

export declare type RGB = {
    r: number;
    g: number;
    b: number;
};

/**
 * @deprecated Use `TextClip` instead.
 */
export declare class RichTextClip extends TextClip {
    layer?: Layer<RichTextClip>;
}

export declare interface RichTextClipProps extends TextClipProps {
}

/**
 * Represents a clockwise rotation in degrees.
 * @public
 */
declare type Rotation = 0 | 90 | 180 | 270;

/**
 * Defines the properties of a rounded rectangle
 */
export declare interface RoundRect extends Rect {
    /**
     * The radius of the rounded corners
     */
    radius?: number | Percent;
}

export declare const SAFE_BROSER_FONTS: readonly ["Helvetica", "Arial", "Arial Black", "Verdana", "Tahoma", "Trebuchet MS", "Impact", "Gill Sans", "Times New Roman", "Georgia", "Palatino", "Baskerville", "Andalé Mono", "Courier", "Lucida", "Monaco", "Bradley Hand", "Brush Script MT", "Luminari", "Comic Sans MS"];

/**
 * Fast sampler options.
 */
export declare type SamplerOptions = {
    /**
     * The number of samples to return.
     */
    length?: number;
    /**
     * The start time in **milliseconds** relative to the beginning of the clip.
     */
    start?: Timestamp | number;
    /**
     * The stop time in **milliseconds** relative to the beginning of the clip.
     */
    stop?: Timestamp | number;
    /**
     * Whether to use a logarithmic scale.
     */
    logarithmic?: boolean;
};

/**
 * Defines the available image formats
 */
export declare type ScreenshotImageFormat = 'webp' | 'png' | 'jpeg';

/**
 * Convert seconds into frames
 */
export declare function secondsToFrames(seconds: number, fps?: number): frame;

export declare function serializable(deserializer?: Deserializer_2, mapTo?: string): (target: any, propertyKey: string) => void;

export declare class Serializer {
    toJSON(exclude?: string[]): unknown;
    fromJSON<K = {}>(obj: K extends string ? never : K): this;
    static fromJSON<T extends Serializer, K = {}>(this: new () => T, obj: K extends string ? never : K): T;
}

/**
 * Defines the shadow properties that
 * can be applied to a shape
 */
export declare interface Shadow {
    /**
     * The color of the shadow
     */
    color?: hex;
    /**
     * The horizontal offset of the shadow
     */
    offsetX?: number;
    /**
     * The vertical offset of the shadow
     */
    offsetY?: number;
    /**
     * The blur of the shadow
     */
    blur?: number;
    /**
     * The opacity of the shadow
     */
    opacity?: number;
}

export declare class ShapeClip extends ShapeClip_base {
    readonly type: ClipType;
    fill: hex;
    strokes: Stroke[];
    get stroke(): Stroke | undefined;
    set stroke(value: Stroke | undefined);
    constructor(props?: ShapeClipProps);
}

declare const ShapeClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent_2;
        _width?: number | Percent_2;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent_2;
        y: number | Percent_2;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent_2;
        set height(value: Percent_2 | number | undefined);
        get width(): number | Percent_2;
        set width(value: Percent_2 | number | undefined);
        get position(): RelativePoint_2;
        set position(value: RelativePoint_2 | "center");
        animate(time: Timestamp_2): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp_2;
        stop: Timestamp_2;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof Clip;

export declare interface ShapeClipProps extends ClipProps, VisualMixinProps {
    fill?: hex;
    stroke?: Stroke;
}

/**
 * This utility creates a file input element and clicks on it
 * @param accept comma separated mime types
 * @example audio/mp3, video/mp4
 * @param multiple enable multiselection
 * @default true
 */
export declare function showFileDialog(accept: string, multiple?: boolean): Promise<File[]>;

export declare type SilenceDetectionOptions = {
    /**
     * If the RMS is below the threshold, the frame is considered silent.
     * @default 0.02
     */
    threshold?: number;
    /**
     * This parameter affects how accurately the algorithm captures short silences.
     * @default 1024
     */
    hopSize?: number;
    /**
     * Setting a minimum duration in **milliseconds** for a silence period helps avoid detecting brief gaps between sounds as silences.
     * @default 500
     */
    minDuration?: number;
};

export declare type SilenceRemoveOptions = {
    /**
     * Adds padding in milliseconds after each detected non-silent segment.
     * This helps prevent cutting off audio too abruptly.
     * @default 500
     */
    padding?: number;
} & SilenceDetectionOptions;

export declare interface SingleColorCaptionPresetConfig extends DefaultCaptionPresetConfig {
    color?: hex;
}

/**
 * Defines the absolute height and width
 */
export declare type Size = {
    width: number;
    height: number;
};

/**
 * setTimeout async/await replacement
 */
export declare function sleep(ms: number): Promise<void>;

export declare class SolarCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    constructor(config?: DefaultCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

export declare class Source {
    static from<T extends BaseSource>(input: MediaInput, options?: SourceOptions_2): Promise<T>;
    /**
     * Restore a checkpoint of the source.
     * @param checkpoint The checkpoint to restore
     * @param sources The sources to use for the restoration
     * @returns The restored source
     */
    static restoreCheckpoint(checkpoint: unknown, options?: SourceOptions_2): Promise<BaseSource>;
}

/**
 * The source base class, representing a resource from which bytes can be read.
 * @public
 */
declare abstract class Source_2 {
    /**
     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call
     * will retrieve the size.
     */
    getSize(): Promise<number>;
    /** Called each time data is requested from the source. */
    onread: ((start: number, end: number) => unknown) | null;
}

export declare type SourceInitOptions = {
    prefetch?: boolean;
};

export declare type SourceOptions = {
    input: MediaInput;
    mimeType: string;
    name?: string;
};

declare type SourceOptions_2 = {
    name?: string;
} & SourceInitOptions;

/**
 * Split an array at the specified position
 */
export declare function splitAt<T>(list: any[] | string, index: number): T;

export declare class SpotlightCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    color: hex;
    constructor(config?: SingleColorCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

export declare class StorageItem<T> extends StorageItem_base {
    private _key;
    private _value;
    private _store;
    loaded: boolean;
    constructor(store: Store, key: string, value: T | Promise<T>);
    get key(): string;
    get value(): T;
    set value(newValue: T);
    private initValue;
}

declare const StorageItem_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent<Error, any>) => void;
            } | undefined;
            update?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
        };
        on<T_1 extends "*" | "error" | "update">(eventType: T_1, callback: (event: EmittedEvent<BaseEvents<Events_2>[T_1], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T_1 extends "*" | "error" | "update">(eventType: T_1, detail: BaseEvents<Events_2>[T_1]): void;
        bubble(target: /*elided*/ any): string;
        resolve(eventType: "*" | "error" | "update"): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
} & typeof Serializer;

export declare class Store {
    readonly storageEngine: Storage;
    readonly namespace?: string;
    constructor(namespace?: string, storageEngine?: Storage);
    define<T>(key: string, defaultValue: T, deserializer?: Deserializer<T>): StorageItem<T>;
    set<T>(key: string, value: T): void;
    get<T>(key: string): T | null;
    remove(key: string): void;
    private getStorageId;
}

/**
 * Defines the stroke properties that
 * can be applied to a shape
 */
export declare interface Stroke {
    /**
     * The color of the stroke
     */
    color?: hex;
    /**
     * The width of the stroke
     */
    width?: number;
    /**
     * The line cap style to use
     */
    lineCap?: LineCap;
    /**
     * The line join style to use
     */
    lineJoin?: LineJoin;
    /**
     * The miter limit to use
     */
    miterLimit?: number;
    /**
     * The opacity of the stroke
     */
    opacity?: number;
}

declare interface StyleOverride {
    /**
     * Defines the start of the style segment
     */
    start: number;
    /**
     * Defines the stop of the style segment, leave
     * undefined when it's the end of the text
     */
    stop?: number;
    /**
     * Defines the style of the text
     */
    style: Partial<TextStyle>;
}

/**
 * List of known subtitle codecs, ordered by encoding preference.
 * @public
 */
declare const SUBTITLE_CODECS: readonly ["webvtt"];

/**
 * Union type of known subtitle codecs.
 * @public
 */
declare type SubtitleCodec = typeof SUBTITLE_CODECS[number];

/**
 * Defines the vertical alignment of the text.
 * This key also sets the anchor point.
 */
export declare type TextAlign = 'left' | 'center' | 'right';

/**
 * Defines the horizonal alignment of the text.
 * This key also sets the anchor point.
 */
export declare type TextBaseline = 'top' | 'bottom' | 'middle' | 'alphabetic';

/**
 * Defines the case of the text
 */
export declare type TextCase = 'upper' | 'lower' | undefined;

export declare class TextClip extends TextClip_base {
    private node;
    readonly type = "text";
    layer?: Layer<TextClip>;
    animations: TextClipAnimationOptions;
    background?: Background;
    /**
     * The width at which text will wrap
     */
    maxWidth: number | Percent | undefined;
    constructor(props?: TextClipProps);
    /**
     * Set the copy for the text object. To split a line you can use '\n'.
     */
    get text(): string;
    set text(value: string);
    /**
     * A fillstyle that will be used on the text '#00FF00'.
     */
    get color(): hex;
    set color(value: hex);
    /**
     * The font to use for the text.
     */
    get font(): Font;
    set font(value: Font);
    /**
     * The casing of the text, e.g. uppercase
     */
    get casing(): TextCase;
    set casing(value: TextCase);
    /**
     * Alignment for multiline text, does not affect single line text.
     */
    get align(): TextAlign;
    set align(value: TextAlign);
    /**
     * The baseline of the text that is rendered.
     */
    get baseline(): TextBaseline;
    set baseline(value: TextBaseline);
    /**
     * An object describing the stroke to apply
     */
    get stroke(): Stroke | undefined;
    set stroke(value: Stroke | undefined);
    get strokes(): Stroke[];
    set strokes(value: Stroke[]);
    /**
     * Set a drop shadow for the text.
     */
    get shadow(): Shadow | undefined;
    set shadow(value: Shadow | Shadow[] | undefined);
    get shadows(): Shadow[];
    set shadows(value: Shadow[]);
    /**
     * The space between lines
     */
    get leading(): number;
    set leading(value: number);
    /**
     * An object describing the glow to apply
     */
    get glow(): Glow | undefined;
    set glow(value: Glow | undefined);
    get styles(): StyleOverride[];
    set styles(value: StyleOverride[]);
    render(renderer: VideoRenderer): void;
    get width(): number;
    set width(_value: number);
    get height(): number;
    set height(_value: number);
    /**
     * Proxy for font.size
     */
    get fontSize(): number;
    set fontSize(value: number);
    get name(): string;
    get position(): RelativePoint;
    set position(value: RelativePoint | 'center');
    get lines(): Token[][];
}

declare const TextClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent;
        _width?: number | Percent;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent;
        y: number | Percent;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent;
        set height(value: Percent | number | undefined);
        get width(): number | Percent;
        set width(value: Percent | number | undefined);
        get position(): RelativePoint;
        set position(value: RelativePoint | "center");
        animate(time: Timestamp_2): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp_2;
        stop: Timestamp_2;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof Clip;

export declare type TextClipAnimationOptions = (KeyframeOptions<'x' | 'y' | 'translateX' | 'translateY', number | Percent> | KeyframeOptions<'opacity' | 'rotation' | 'scale' | 'scaleX' | 'scaleY' | 'fontSize' | 'leading', number> | KeyframeOptions<'text', string> | KeyframeOptions<'color', hex>)[];

export declare interface TextClipProps extends ClipProps, Omit<VisualMixinProps, 'width' | 'height'>, Partial<TextStyle> {
    text?: string;
    align?: TextAlign;
    baseline?: TextBaseline;
    stroke?: Stroke;
    shadow?: Shadow | Shadow[];
    leading?: number;
    background?: Background;
    styles?: StyleOverride[];
    maxWidth?: number | Percent;
    animations?: TextClipAnimationOptions;
}

/**
 * Defines the properties of text
 */
export declare interface TextOptions {
    /**
     * The font to use
     */
    font?: Font;
    /**
     * The color of the text
     */
    color?: string;
    /**
     * The alignment of the text
     */
    alignment?: TextAlign;
    /**
     * The baseline of the text
     */
    baseline?: TextBaseline;
}

declare interface TextStyle {
    font: Font;
    fontSize: number;
    color: hex;
    shadows: Shadow[];
    strokes: Stroke[];
    opacity: number;
    glow?: Glow;
    casing: TextCase;
}

export declare type Time = `${number}ms` | `${number}s` | `${number}f` | `${number}min` | `${number}:${number}` | `${number}:${number}:${number}` | number | Timestamp;

/**
 * Defines a time indication object that uses
 * milliseconds rounded to the nearest integer
 * and 30fps internally. By default the time is 0
 */
export declare class Timestamp implements Serializer {
    /**
     * Time state in **milliseconds**
     */
    private time;
    /**
     * Create a new timestamp from various time units
     * @param millis - Time in milliseconds
     * @param seconds - Time in seconds
     * @param minutes - Time in minutes
     * @param hours - Time in hours
     */
    constructor(millis?: number, seconds?: number, minutes?: number, hours?: number);
    /**
     * Base unit of the timestamp
     */
    get millis(): number;
    set millis(value: number);
    /**
     * Defines the time in frames at the
     * current frame rate
     */
    get frames(): frame;
    set frames(value: frame);
    /**
     * Convert the timestamp to seconds
     */
    get seconds(): number;
    set seconds(value: number);
    /**
     * Equivalent to millis += x
     */
    addMillis(value: number): this;
    /**
     * Equivalent to frames += x
     */
    addFrames(value: frame): this;
    /**
     * add two timestamps the timestamp being added will adapt
     * its fps to the current fps
     * @returns A new Timestamp instance with the added frames
     */
    add(time: Timestamp): Timestamp;
    /**
     * subtract two timestamps timestamp being subtracted
     * will adapt its fps to the current fps
     * @returns A new Timestamp instance with the added frames
     */
    subtract(time: Timestamp): Timestamp;
    /**
     * Create a new timestamp from frames
     */
    static fromFrames(value: frame, fps?: number): Timestamp;
    /**
     * get a copy of the object
     */
    copy(): Timestamp;
    toJSON(): number;
    fromJSON<K = {}>(obj: K extends unknown ? never : K): this;
    static fromJSON(value: number): Timestamp;
}

/**
 * Convert an alpha value to hex
 * @param alpha A value between 0 and 1
 * @returns Alpha as 2 digit hex
 * @example FF
 */
export declare function toHex(alpha: number): string;

/**
 * Union type of all track types.
 * @public
 */
declare type TrackType = typeof ALL_TRACK_TYPES[number];

export declare class Transcript implements Serializer {
    id: string;
    language: Language;
    groups: WordGroup[];
    get text(): string;
    get words(): Word[];
    constructor(groups?: WordGroup[], language?: Language);
    /**
     * Iterate over all words in groups
     */
    iter({ count, duration, length }: GeneratorOptions): Generator<WordGroup, void, unknown>;
    /**
     * This method will optimize the transcipt for display
     */
    optimize(): this;
    /**
     * Convert the transcript into a SRT compatible
     * string and downloadable blob
     */
    toSRT(options?: GeneratorOptions): {
        text: string;
        blob: Blob;
    };
    toJSON(): Captions;
    /**
     * Create a new Transcript containing the
     * first `{count}` words
     * @param count Defines the number of words required
     * @param startAtZero Defines if the first word should start at 0 milliseconds
     * @returns A new Transcript instance
     */
    slice(count: number, startAtZero?: boolean): Transcript;
    /**
     * Create a deep copy of the transcript
     * @returns A new Transcript instance
     */
    copy(): Transcript;
    static fromJSON(data: Captions): Transcript;
    /**
     * Create a Transcript from an input medium of the form:
     * `{ token: string; start: number; stop: number; }[][]`
     * @param input The input medium, can be a URL, Blob, or an array of captions
     * @returns A Transcript with processed captions
     */
    static from(input: MediaInput | Captions): Promise<Transcript>;
    fromJSON<K = {}>(obj: K extends string ? never : K): this;
}

/**
 * Defines the properties of a transform
 */
export declare interface Transform {
    /**
     * The translation of the transform
     */
    translate?: RelativePoint;
    /**
     * The scale of the transform
     */
    scale?: Point;
    /**
     * The rotation of the transform
     */
    rotate?: number;
}

export declare function transformText(text: string, textCase?: TextCase): string;

export declare type TransitionConfig = {
    duration: Time;
    type: TransitionType;
};

export declare type TransitionType = 'dissolve' | 'slide-from-right' | 'slide-from-left' | 'fade-to-black' | 'fade-to-white';

declare namespace types {
    export {
        FontFamily,
        FontSubset,
        FontType,
        FontSource,
        FontSources,
        WebfontProperties
    }
}

/**
 * Short unique id (not as secure as uuid 4 though)
 */
export declare function uid(): string | undefined;

/**
 * Defines a uuid 4
 */
export declare type uuid = `${string}-${string}-${string}-${string}-${string}`;

export declare class ValidationError extends BaseError {
}

export declare class VerdantCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    color: hex;
    constructor(config?: SingleColorCaptionPresetConfig);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

/**
 * List of known video codecs, ordered by encoding preference.
 * @public
 */
declare const VIDEO_CODECS: readonly ["avc", "hevc", "vp9", "av1", "vp8"];

export declare class VideoClip extends VideoClip_base {
    _keepAspectRatio: boolean;
    readonly type = "video";
    layer?: Layer<VideoClip>;
    source?: VideoSource;
    private videoDecoder?;
    animations: VideoClipAnimationOptions;
    constructor(input?: MediaInput | VideoSource, props?: VideoClipProps);
    init(audio: AudioRenderer): Promise<void>;
    seek(audio: AudioRenderer): Promise<void>;
    update(audio: AudioRenderer): Promise<void>;
    render(video: VideoRenderer): void;
    exit(): Promise<void>;
}

declare const VideoClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent_2;
        _width?: number | Percent_2;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent_2;
        y: number | Percent_2;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent_2;
        set height(value: Percent_2 | number | undefined);
        get width(): number | Percent_2;
        set width(value: Percent_2 | number | undefined);
        get position(): RelativePoint_2;
        set position(value: RelativePoint_2 | "center");
        animate(time: Timestamp_2): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp_2;
        stop: Timestamp_2;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof AudioClip;

export declare type VideoClipAnimationOptions = VisualMixinAnimationOptions;

export declare interface VideoClipProps extends AudioClipProps, VisualMixinProps {
    animations?: VideoClipAnimationOptions;
}

/**
 * Union type of known video codecs.
 * @public
 */
declare type VideoCodec = typeof VIDEO_CODECS[number];

declare interface VideoConfig {
    /**
     * Defines the codec to use for the video
     * @default 'avc'
     */
    codec?: VideoCodec;
    /**
     * The full codec string as specified in the WebCodecs API Codec Registry.
     */
    fullCodecString?: string;
    /**
     * Enable video encoding
     * @default true
     */
    enabled?: boolean;
    /**
     * Defines the bitrate at which the video should be rendered at
     * @default 10e6
     */
    bitrate?: number;
    /**
     * Defines the fps at which the composition will be rendered
     * @default 30
     */
    fps?: number;
    /**
     * Multiplier of the composition size
     * @example 2 // 1080p -> 4K
     * @default 1 // 1080p -> 1080p
     */
    resolution?: number;
}

/**
 * 2D context based video renderer
 */
export declare class VideoRenderer extends Serializer {
    _background: hex | 'transparent';
    /**
     * The canvas element
     */
    readonly canvas: HTMLCanvasElement;
    /**
     * The main 2d context of the canvas
     */
    readonly context: CanvasRenderingContext2D;
    /**
     * The resolution of the canvas
     */
    resolution: number;
    /**
     * The width of the canvas
     * Initially 0 so the constructor will set the width
     */
    width: number;
    /**
     * The height of the canvas
     * Initially 0 so the constructor will set the height
     */
    height: number;
    constructor({ width, height, background, resolution, }?: VideoRendererInit);
    /**
     * The background color of the canvas
     */
    get background(): hex | 'transparent';
    set background(background: hex | 'transparent');
    /**
     * Resize the canvas
     */
    resize(width?: number, height?: number, resolution?: number): this;
    clear(region?: Rect): this;
    rect(rect: RoundRect): this;
    circle(circle: Circle | Ellipse): this;
    image(image: CanvasImageSourceWebCodecs, options: ImageOptions): this;
    clip(data?: Path2D | Mask, fillRule?: FillRule): this;
    opacity(opacity: number): this;
    transform(transform?: Transform): this;
    blendMode(mode?: BlendMode): this;
    save(): this;
    restore(): this;
    filter(filter?: string): this;
    fill(options?: FillOptions, draw?: boolean): this;
    shadow(options?: Shadow): this;
    stroke(options?: Stroke, draw?: boolean): this;
    /**
     * Add the renderer to the dom
     */
    mount(element: HTMLElement): void;
    /**
     * Remove the renderer from the dom
     */
    unmount(): void;
    private createGradient;
    /**
     * Draw a watermark on the canvas
     */
    watermark(text?: string): void;
    /**
     * The scale of the text
     * @deprecated
     */
    textScale: number;
    /**
     * @deprecated use Text node instead
     */
    text(options: TextOptions): this;
    /**
     * @deprecated use Text node instead
     */
    strokeText(text: string, options: RelativePoint): this;
    /**
     * @deprecated use Text node instead
     */
    fillText(text: string, options: RelativePoint): this;
    /**
     * @deprecated use Text node instead
     */
    measureText(text: string, options: Font): TextMetrics;
    /**
     * @deprecated use Text node instead
     */
    private createFontString;
}

declare type VideoRendererInit = {
    width?: number;
    height?: number;
    background?: hex | 'transparent';
    resolution?: number;
};

declare type VideoSettings = {
    height: number;
    width: number;
    fps: number;
    bitrate: number;
};

export declare class VideoSource extends VideoSource_base {
    readonly type: ClipType;
    element: HTMLVideoElement;
    init(options?: SourceInitOptions): Promise<void>;
    thumbnail(): Promise<HTMLVideoElement>;
    thumbnailsInRange(options: {
        startTime: Time;
        endTime: Time;
        count: number;
        width: number;
        height: number;
    }): AsyncGenerator<WrappedCanvas | null, void, unknown>;
}

declare const VideoSource_base: {
    new (...args: any[]): {
        height: int_2;
        width: int_2;
        readonly aspectRatio: number;
        id: string;
        data: Record<string, unknown>;
        readonly type: ClipType;
        mimeType: string;
        input: MediaInput_2;
        name: string;
        createdAt: Date;
        init(options?: SourceInitOptions): Promise<void>;
        arrayBuffer(): Promise<ArrayBuffer>;
        download(): Promise<void>;
        thumbnail(): Promise<HTMLElement>;
        createCheckpoint(): Promise<unknown>;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof AudioSource;

declare interface VisualBase extends Serializer {
    layer?: {
        composition?: {
            height?: number;
            width?: number;
        };
    };
    animations: ClipAnimationOptions;
    start: Timestamp;
    stop: Timestamp;
}

export declare function VisualMixin<T extends Constructor<VisualBase>>(Base: T): {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        };
        _height?: number | Percent;
        _width?: number | Percent;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask;
        /**
         * The anchor x position, proxy for the anchor.x property
         * @default 0
         */
        anchorX: number;
        /**
         * The anchor y position, proxy for the anchor.y property
         * @default 0
         */
        anchorY: number;
        /**
         * The scale x factor
         * @default 1
         */
        scaleX: number;
        /**
         * The scale y factor
         * @default 1
         */
        scaleY: number;
        /**
         * The translate x factor
         * @default 0
         */
        translateX: number;
        /**
         * The translate y factor
         * @default 0
         */
        translateY: number;
        /**
         * The position of the clip on the x axis.
         * @default 0
         */
        x: number | Percent;
        /**
         * The position of the clip on the y axis.
         * @default 0
         */
        y: number | Percent;
        /**
         * Defines the rotation of the clip in degrees
         * @default 0
         * @example 90
         */
        rotation: number;
        /**
         * Defines the opacity of the clip as a number
         * between 0 and 1
         * @default 100
         */
        opacity: number;
        /**
         * Defines the filter property of the Canvas 2D API. It provides
         * filter effects such as blurring and grayscaling.
         * It is similar to the CSS filter property and accepts the same values.
         * https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/filter
         */
        filter?: string;
        /**
         * Sets the type of compositing operation to apply when drawing new shapes.
         * https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/globalCompositeOperation
         * @default 'source-over'
         */
        blendMode?: BlendMode;
        /**
         * 2D position offset of the clip.
         * @default { x: 0, y: 0 }
         */
        get translate(): Point;
        set translate(value: Point | number);
        /**
         * The anchor sets the origin point of the clip. Setting the anchor to (0.5,0.5)
         * means the clips' origin is centered. Setting the anchor to (1,1) would mean
         * the clips' origin point will be the bottom right corner. If you pass only
         * single parameter, it will set both x and y to the same value.
         */
        get anchor(): Point;
        set anchor(value: Point | number);
        /**
         * The scale factors of this object along the local coordinate axes.
         * Will be added to the scale applied by setting height and/or width
         * @default { x: 1, y: 1 }
         */
        get scale(): Point;
        set scale(value: Point | number);
        /**
         * Defines a region of the clip to be masked.
         */
        mask: Mask | undefined;
        /**
         * If true, the clip will keep the aspect ratio.
         * Will be set to false if both height and width are set.
         * @default true
         */
        keepAspectRatio: boolean;
        /**
         * Gets the effective aspect ratio, using custom ratio if set, otherwise falling back to source
         */
        get aspectRatio(): number;
        /**
         * Sets a custom aspect ratio that overrides the source aspect ratio when free transform is enabled
         */
        set aspectRatio(value: number | undefined);
        /**
         * Gets the current height of the clip
         */
        get height(): number | Percent;
        set height(value: Percent | number | undefined);
        /**
         * Gets the current width of the clip
         */
        get width(): number | Percent;
        set width(value: Percent | number | undefined);
        /**
         * The coordinate of the object relative to the local coordinates of the parent.
         * @default { x: 0, y: 0 }
         */
        get position(): RelativePoint;
        set position(value: RelativePoint | "center");
        animate(time: Timestamp): /*elided*/ any;
        /**
         * Gets the size of the clip in absolute units
         */
        readonly size: Size;
        /**
         * Calculates the absolute coordinates of the shape's corners, taking into account
         * position, anchor point, translation, scale, and rotation. Assumes scale of 1.
         * @returns Object containing the coordinates of all four corners
         */
        readonly bounds: [Point, Point, Point, Point];
        /**
         * @deprecated Use keepAspectRatio instead
         */
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions;
        start: Timestamp;
        stop: Timestamp;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & T;

export declare type VisualMixinAnimationOptions = (KeyframeOptions<'x' | 'y' | 'height' | 'width' | 'translateX' | 'translateY', number | Percent> | KeyframeOptions<'opacity' | 'rotation' | 'scale' | 'scaleX' | 'scaleY' | 'anchorX' | 'anchorY', number>)[];

export declare interface VisualMixinProps {
    rotation?: number;
    opacity?: number;
    translate?: Point | number;
    translateX?: number | Percent;
    translateY?: number | Percent;
    position?: RelativePoint | 'center';
    x?: number | Percent;
    y?: number | Percent;
    scale?: Point | number;
    scaleX?: number;
    scaleY?: number;
    height?: Percent | number;
    width?: Percent | number;
    anchor?: Point | number;
    anchorX?: number;
    anchorY?: number;
    freeTransform?: boolean;
    keepAspectRatio?: boolean;
    filter?: string;
    blendMode?: BlendMode;
    mask?: Mask;
}

export declare function VisualSourceMixin<T extends Constructor<BaseSource>>(Base: T): {
    new (...args: any[]): {
        /**
         * The height of the source
         */
        height: int;
        /**
         * The width of the source
         */
        width: int;
        /**
         * The aspect ratio of the source
         */
        readonly aspectRatio: number;
        id: string;
        data: Record<string, unknown>;
        readonly type: ClipType_2;
        mimeType: string;
        input: MediaInput_2;
        name: string;
        createdAt: Date;
        init(options?: SourceInitOptions_3): Promise<void>;
        arrayBuffer(): Promise<ArrayBuffer>;
        download(): Promise<void>;
        thumbnail(): Promise<HTMLElement>;
        createCheckpoint(): Promise<unknown>;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & T;

export declare interface WaveformBar {
    width: number;
    gap: number;
    radius?: number;
}

export declare class WaveformClip extends WaveformClip_base {
    readonly type = "waveform";
    layer?: Layer<AudioClip>;
    animations: WaveformClipAnimationOptions;
    readonly sampleRate = 8000;
    fill: FillOptions;
    bar: WaveformBar;
    smoothing: number;
    magnitude: number;
    private barHeights;
    private channelData?;
    private time;
    constructor(input?: MediaInput | AudioSource, props?: WaveformClipProps);
    init(): Promise<void>;
    enter(): Promise<void>;
    update(audio: AudioRenderer): Promise<void>;
    render(renderer: VideoRenderer): Promise<void>;
    private updateBarHeights;
}

declare const WaveformClip_base: {
    new (...args: any[]): {
        source?: {
            height: number;
            width: number;
            aspectRatio: number;
        } | undefined;
        _height?: number | Percent_2;
        _width?: number | Percent_2;
        _aspectRatio?: number;
        _keepAspectRatio: boolean;
        _mask?: Mask_2;
        anchorX: number;
        anchorY: number;
        scaleX: number;
        scaleY: number;
        translateX: number;
        translateY: number;
        x: number | Percent_2;
        y: number | Percent_2;
        rotation: number;
        opacity: number;
        filter?: string;
        blendMode?: BlendMode_2;
        get translate(): Point_2;
        set translate(value: Point_2 | number);
        get anchor(): Point_2;
        set anchor(value: Point_2 | number);
        get scale(): Point_2;
        set scale(value: Point_2 | number);
        mask: Mask_2 | undefined;
        keepAspectRatio: boolean;
        get aspectRatio(): number;
        set aspectRatio(value: number | undefined);
        get height(): number | Percent_2;
        set height(value: Percent_2 | number | undefined);
        get width(): number | Percent_2;
        set width(value: Percent_2 | number | undefined);
        get position(): RelativePoint_2;
        set position(value: RelativePoint_2 | "center");
        animate(time: Timestamp): /*elided*/ any;
        readonly size: Size_2;
        readonly bounds: [Point_2, Point_2, Point_2, Point_2];
        freeTransform: boolean;
        layer?: {
            composition?: {
                height?: number;
                width?: number;
            };
        };
        animations: ClipAnimationOptions_2;
        start: Timestamp;
        stop: Timestamp;
        toJSON(exclude?: string[]): unknown;
        fromJSON<K = {}>(obj: K extends string ? never : K): /*elided*/ any;
    };
} & typeof AudioClip;

export declare type WaveformClipAnimationOptions = VisualMixinAnimationOptions;

export declare interface WaveformClipProps extends Omit<AudioClipProps, 'volume'>, VisualMixinProps {
    animations?: WaveformClipAnimationOptions;
    bar?: WaveformBar;
    fill?: FillOptions;
    sampleRate?: number;
    smoothing?: number;
    magnitude?: number;
}

declare class WebAudioDecoder extends WebAudioDecoder_base {
    private input;
    private buffers;
    constructor(input: MediaInput);
    /**
     * Decodes an audio file or URL and returns a resampled AudioBuffer.
     * @param input - Either a File, Blob, or URL string.
     * @returns Promise<AudioBuffer>
     */
    decode(numberOfChannels?: number, sampleRate?: number, cache?: boolean): Promise<AudioBuffer>;
    dispose(): Promise<void>;
}

declare const WebAudioDecoder_base: {
    new (...args: any[]): {
        _handlers: {
            '*'?: {
                [x: string]: (event: EmittedEvent<any, any>) => void;
            } | undefined;
            error?: {
                [x: string]: (event: EmittedEvent<Error, any>) => void;
            } | undefined;
        };
        on<T extends "*" | "error">(eventType: T, callback: (event: EmittedEvent<    {
        '*': any;
        error: Error;
        }[T], /*elided*/ any>) => void): string;
        off(id?: string | "*", ...ids: string[]): void;
        emit<T extends "*" | "error">(eventType: T, detail: {
            '*': any;
            error: Error;
        }[T]): void;
        bubble(target: {
            _handlers: {
                '*'?: {
                    [x: string]: (event: EmittedEvent<any, any>) => void;
                } | undefined;
                error?: {
                    [x: string]: (event: EmittedEvent<Error, any>) => void;
                } | undefined;
            };
            on<T extends "*" | "error">(eventType: T, callback: (event: EmittedEvent<    {
            '*': any;
            error: Error;
            }[T], /*elided*/ any>) => void): string;
            off(id?: string | "*", ...ids: string[]): void;
            emit<T extends "*" | "error">(eventType: T, detail: {
                '*': any;
                error: Error;
            }[T]): void;
            bubble(target: /*elided*/ any): string;
            resolve(eventType: "*" | "error"): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
        }): string;
        resolve(eventType: "*" | "error"): (resolve: (value: unknown) => void, reject: (reason?: any) => void) => void;
    };
};

/**
 * Defines the arguments to identify
 * a default webfont
 */
export declare type WebfontProperties<T extends keyof typeof WebFonts> = {
    family: T;
    weight: typeof WebFonts[T]['weights'][number];
    size?: number;
};

export declare const WebFonts: {
    readonly 'The Bold Font': {
        readonly weights: readonly ["500"];
        readonly url: "https://diffusion-studio-public.s3.eu-central-1.amazonaws.com/fonts/the-bold-font.ttf";
    };
    readonly 'Komika Axis': {
        readonly weights: readonly ["400"];
        readonly url: "https://diffusion-studio-public.s3.eu-central-1.amazonaws.com/fonts/komika-axis.ttf";
    };
    readonly Geologica: {
        readonly weights: readonly ["100", "200", "300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/geologica/v1/oY1l8evIr7j9P3TN9YwNAdyjzUyDKkKdAGOJh1UlCDUIhAIdhCZOn1fLsig7jfvCCPHZckUWE1lELWNN-w.woff2";
    };
    readonly Nunito: {
        readonly weights: readonly ["200", "300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/nunito/v26/XRXV3I6Li01BKofINeaBTMnFcQ.woff2";
    };
    readonly Figtree: {
        readonly weights: readonly ["300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/figtree/v5/_Xms-HUzqDCFdgfMm4S9DaRvzig.woff2";
    };
    readonly Urbanist: {
        readonly weights: readonly ["100", "200", "300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/urbanist/v15/L0x-DF02iFML4hGCyMqlbS1miXK2.woff2";
    };
    readonly Montserrat: {
        readonly weights: readonly ["100", "200", "300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/montserrat/v26/JTUSjIg1_i6t8kCHKm459WlhyyTh89Y.woff2";
    };
    readonly Bangers: {
        readonly weights: readonly ["400"];
        readonly url: "https://fonts.gstatic.com/s/bangers/v20/FeVQS0BTqb0h60ACH55Q2J5hm24.woff2";
    };
    readonly Chewy: {
        readonly weights: readonly ["400"];
        readonly url: "https://fonts.gstatic.com/s/chewy/v18/uK_94ruUb-k-wn52KjI9OPec.woff2";
    };
    readonly 'Source Code Pro': {
        readonly weights: readonly ["200", "300", "400", "500", "600", "700", "800", "900"];
        readonly url: "https://fonts.gstatic.com/s/sourcecodepro/v22/HI_SiYsKILxRpg3hIP6sJ7fM7PqlPevWnsUnxg.woff2";
    };
};

export declare class WhisperCaptionPreset extends CaptionPreset {
    generatorOptions: GeneratorOptions;
    color: hex;
    constructor(config?: Partial<SingleColorCaptionPresetConfig>);
    apply(layer: Layer, transcript: Transcript, delay: Timestamp): Promise<void>;
}

export declare class Word {
    /**
     * A unique identifier for the word
     */
    id: `${string}-${string}-${string}-${string}-${string}`;
    /**
     * Defines the text to be displayed
     */
    text: string;
    /**
     * Defines the time stamp at
     * which the text is spoken
     */
    start: Timestamp;
    /**
     * Defines the time stamp at
     * which the text was spoken
     */
    stop: Timestamp;
    /**
     * Defines the confidence of
     * the predicition
     */
    confidence?: number;
    /**
     * Create a new Word object
     * @param text The string contents of the word
     * @param start Start in **milliseconds**
     * @param stop Stop in **milliseconds**
     * @param confidence Predicition confidence
     */
    constructor(text: string, start: number, stop: number, confidence?: number);
    /**
     * Defines the time between start
     * and stop returned as a timestamp
     */
    get duration(): Timestamp;
}

export declare class WordGroup {
    words: Word[];
    constructor(words?: Word[]);
    get duration(): Timestamp;
    get text(): string;
    get start(): Timestamp;
    get stop(): Timestamp;
}

declare type WriteStreamCallback = (data: Uint8Array, position: number) => void;

export { }
